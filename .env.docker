# AWS LLM RAGA Project - Docker Environment Configuration

# Database Configuration
POSTGRES_PASSWORD=ragpassword123

# AWS S3 Configuration
AWS_ACCESS_KEY_ID=your_access_key_id
AWS_SECRET_ACCESS_KEY=your_secret_access_key
AWS_S3_BUCKET=your-s3-bucket-name
AWS_REGION=us-east-1

# LLM Provider Configuration
PROVIDER=openai
MODEL=gpt-3.5-turbo
OPENAI_API_KEY=your_openai_api_key
GEMINI_API_KEY=your_gemini_api_key

# Advanced Chunking Configuration
CHUNKING_METHOD=adaptive
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CONTEXT_LENGTH=4000
USE_RECURSIVE_CHUNKING=true
SEMANTIC_THRESHOLD=0.7
LLM_PROVIDER=openai
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Application Configuration
FLASK_ENV=production
FLASK_DEBUG=false

# Database initialization (set to false to skip schema creation)
SKIP_DB_INIT=false
