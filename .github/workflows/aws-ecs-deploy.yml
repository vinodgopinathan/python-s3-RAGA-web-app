name: Deploy to AWS ECS

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'development'
        type: choice
        options:
        - development
        - staging

env:
  AWS_REGION: us-east-1
  APP_NAME: python-s3-webapp-v2
  IMAGE_TAG: ${{ github.sha }}
  ENVIRONMENT: ${{ github.event.inputs.environment || 'development' }}

jobs:
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    outputs:
      alb-dns: ${{ steps.get-alb-dns.outputs.alb-dns }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create/Update CloudFormation Stack
        run: |
          # Check if stack exists and handle rollback states
          echo "Checking stack status..."
          STACK_STATUS=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].StackStatus' \
            --output text 2>/dev/null || echo "DOES_NOT_EXIST")
          
          echo "Current stack status: $STACK_STATUS"
          
          # If stack is in failed/rollback state, delete it first
          if [[ "$STACK_STATUS" == *"ROLLBACK"* ]] || [[ "$STACK_STATUS" == *"FAILED"* ]]; then
            echo "Stack is in failed/rollback state: $STACK_STATUS. Deleting for clean deployment..."
            aws cloudformation delete-stack --stack-name ${{ env.APP_NAME }}-stack
            echo "Waiting for stack deletion to complete (max 5 minutes)..."
            timeout 300 aws cloudformation wait stack-delete-complete --stack-name ${{ env.APP_NAME }}-stack || {
              echo "Stack deletion timed out after 5 minutes. Proceeding anyway..."
              # Check if stack still exists
              STACK_STATUS=$(aws cloudformation describe-stacks \
                --stack-name ${{ env.APP_NAME }}-stack \
                --query 'Stacks[0].StackStatus' \
                --output text 2>/dev/null || echo "DOES_NOT_EXIST")
              if [[ "$STACK_STATUS" != "DOES_NOT_EXIST" ]]; then
                echo "Warning: Stack still exists in state: $STACK_STATUS"
                echo "Manual cleanup may be required"
                exit 1
              fi
            }
            echo "Stack deleted successfully"
            STACK_STATUS="DOES_NOT_EXIST"
          elif [[ "$STACK_STATUS" != "DOES_NOT_EXIST" ]]; then
            echo "Stack exists in state: $STACK_STATUS. Will update existing stack."
          fi
          
          # Validate the template
          echo "Validating CloudFormation template..."
          aws cloudformation validate-template \
            --template-body file://infrastructure/cloudformation.yml

          # Create/Update the stack with detailed error handling
          echo "Deploying CloudFormation stack..."
          if ! aws cloudformation deploy \
            --template-file infrastructure/cloudformation.yml \
            --stack-name ${{ env.APP_NAME }}-stack \
            --parameter-overrides \
              ApplicationName=${{ env.APP_NAME }} \
              Environment=${{ env.ENVIRONMENT }} \
            --capabilities CAPABILITY_NAMED_IAM \
            --no-fail-on-empty-changeset; then
            
            # If deployment fails, get the stack events to help with debugging
            echo "Stack deployment failed. Recent stack events:"
            aws cloudformation describe-stack-events \
              --stack-name ${{ env.APP_NAME }}-stack \
              --query 'StackEvents[?ResourceStatus==`CREATE_FAILED` || ResourceStatus==`UPDATE_FAILED` || ResourceStatus==`ROLLBACK_IN_PROGRESS` || ResourceStatus==`ROLLBACK_COMPLETE`].[LogicalResourceId,ResourceStatus,ResourceStatusReason]' \
              --output table
            exit 1
          fi

          # Wait for stack creation/update to complete
          echo "Waiting for stack to complete..."
          if aws cloudformation describe-stacks --stack-name ${{ env.APP_NAME }}-stack --query 'Stacks[0].StackStatus' --output text | grep -q 'UPDATE'; then
            aws cloudformation wait stack-update-complete --stack-name ${{ env.APP_NAME }}-stack
          else
            aws cloudformation wait stack-create-complete --stack-name ${{ env.APP_NAME }}-stack
          fi

          # Verify the stack status
          STACK_STATUS=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].StackStatus' \
            --output text)

          echo "Stack status: $STACK_STATUS"
          if [[ $STACK_STATUS != *"COMPLETE"* ]]; then
            echo "Stack did not complete successfully"
            exit 1
          fi

      - name: Get ALB DNS Name
        id: get-alb-dns
        run: |
          ALB_DNS=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`LoadBalancerDNS`].OutputValue' \
            --output text)
          # Verify ALB DNS is not empty
          if [ -z "$ALB_DNS" ]; then
            echo "Error: ALB DNS Name is empty. Check your CloudFormation stack."
            exit 1
          fi
          echo "Successfully retrieved ALB DNS Name: $ALB_DNS"
          # Set the output for later jobs
          echo "alb-dns=${ALB_DNS}" >> $GITHUB_OUTPUT
      

  build-and-push:
    needs: deploy-infrastructure
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.build-push.outputs.image-tag }}
      alb-dns: ${{ steps.build-push.outputs.alb-dns }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push images using docker-compose
        id: build-push
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          REACT_APP_API_URL: http://${{ needs.deploy-infrastructure.outputs.alb-dns }}
          API_URL: http://${{ needs.deploy-infrastructure.outputs.alb-dns }}
          IMAGE_TAG: ${{ github.sha }}
          AWS_REGION: ${{ env.AWS_REGION }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Extract AWS Account ID from ECR registry URL
          AWS_ACCOUNT_ID=$(echo $ECR_REGISTRY | cut -d. -f1)
          
          # Debug environment variables
          echo "Debug: Environment Variables"
          echo "ECR_REGISTRY: $ECR_REGISTRY"
          echo "AWS_ACCOUNT_ID: $AWS_ACCOUNT_ID"
          echo "IMAGE_TAG: $IMAGE_TAG"
          echo "AWS_REGION: $AWS_REGION"
          
          if [ -z "$ECR_REGISTRY" ]; then
            echo "Error: ECR_REGISTRY is not set. Login to ECR might have failed."
            exit 1
          fi
          
          if [ -z "$IMAGE_TAG" ]; then
            echo "Error: IMAGE_TAG is not set"
            exit 1
          fi
          
          # Export the full image names with tags
          BACKEND_IMAGE="${ECR_REGISTRY}/python-s3-webapp-backend:${IMAGE_TAG}"
          FRONTEND_IMAGE="${ECR_REGISTRY}/python-s3-webapp-frontend:${IMAGE_TAG}"
          
          echo "Building images:"
          echo "Backend image: ${BACKEND_IMAGE}"
          echo "Frontend image: ${FRONTEND_IMAGE}"
          
          # Set the environment variables for docker-compose
          export ECR_REGISTRY="${ECR_REGISTRY}"
          export IMAGE_TAG="${IMAGE_TAG}"
          
          # Create ECR repositories if they don't exist
          aws ecr describe-repositories --repository-names python-s3-webapp-backend || \
            aws ecr create-repository --repository-name python-s3-webapp-backend
          aws ecr describe-repositories --repository-names python-s3-webapp-frontend || \
            aws ecr create-repository --repository-name python-s3-webapp-frontend
          
          # Build Docker images with detailed output
          echo "Building Docker images..."
          if ! DOCKER_BUILDKIT=1 docker compose -f docker-compose.ecs.yml build --progress=plain; then
            echo "Error: Failed to build Docker images. Check the build output above for details."
            exit 1
          fi
          
          # Verify images were built
          echo "Verifying local images..."
          if ! docker image inspect "${ECR_REGISTRY}/python-s3-webapp-backend:${IMAGE_TAG}" >/dev/null 2>&1; then
            echo "Error: Backend image was not built successfully"
            exit 1
          fi
          if ! docker image inspect "${ECR_REGISTRY}/python-s3-webapp-frontend:${IMAGE_TAG}" >/dev/null 2>&1; then
            echo "Error: Frontend image was not built successfully"
            exit 1
          fi
          
          # Push images to ECR (images are already tagged with ECR registry names)
          echo "Pushing Docker images to ECR..."
          if ! docker push ${BACKEND_IMAGE}; then
            echo "Error: Failed to push backend image to ECR"
            exit 1
          fi
          
          if ! docker push ${FRONTEND_IMAGE}; then
            echo "Error: Failed to push frontend image to ECR"
            exit 1
          fi
          
          # Verify the push was successful by checking ECR
          echo "Verifying images in ECR..."
          sleep 5  # Give ECR a moment to register the images
          
          # Verify backend image
          if ! aws ecr describe-images \
            --repository-name python-s3-webapp-backend \
            --image-ids imageTag=${IMAGE_TAG} > /dev/null 2>&1; then
            echo "Error: Backend image not found in ECR after push"
            exit 1
          fi
          
          # Verify frontend image
          if ! aws ecr describe-images \
            --repository-name python-s3-webapp-frontend \
            --image-ids imageTag=${IMAGE_TAG} > /dev/null 2>&1; then
            echo "Error: Frontend image not found in ECR after push"
            exit 1
          fi
          
          echo "Successfully verified images in ECR"
          
          # Set and verify outputs for later jobs
          echo "image-tag=${IMAGE_TAG}" >> "$GITHUB_OUTPUT"
          echo "alb-dns=${{ needs.deploy-infrastructure.outputs.alb-dns }}" >> "$GITHUB_OUTPUT"

          # Debug the outputs being set
          echo "Setting outputs with these values:"
          echo "image-tag=${IMAGE_TAG}"

          # Verify outputs were set
          if [[ ! -v GITHUB_OUTPUT ]] || [[ ! -f "$GITHUB_OUTPUT" ]]; then
            echo "Error: GITHUB_OUTPUT environment variable or file not found"
            exit 1
          fi

          echo "Content of GITHUB_OUTPUT file:"
          cat "$GITHUB_OUTPUT"
          
          echo "Successfully built and pushed images to ECR:"
          echo "Backend: ${BACKEND_IMAGE}"
          echo "Frontend: ${FRONTEND_IMAGE}"

  deploy-ecs:
    needs: build-and-push
    name: Deploy to ECS
    runs-on: ubuntu-latest

    steps:
      - name: Debug needs context
        run: |
          echo "needs context: ${{ toJSON(needs) }}"
          echo "alb-dns output: ${{ needs.build-and-push.outputs.alb-dns }}"
          echo "image-tag output: ${{ needs.build-and-push.outputs.image-tag }}"

      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get CloudFormation outputs
        id: get-outputs
        run: |
          EXECUTION_ROLE=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`ECSTaskExecutionRole`].OutputValue' \
            --output text)
          TASK_ROLE=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`ECSTaskRole`].OutputValue' \
            --output text)
          SUBNET_IDS=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`PublicSubnets`].OutputValue' \
            --output text)
          SECURITY_GROUP_ID=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`ECSSecurityGroup`].OutputValue' \
            --output text)
          FRONTEND_TARGET_GROUP=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`ALBTargetGroup`].OutputValue' \
            --output text)
          BACKEND_TARGET_GROUP=$(aws cloudformation describe-stacks \
            --stack-name ${{ env.APP_NAME }}-stack \
            --query 'Stacks[0].Outputs[?OutputKey==`BackendTargetGroup`].OutputValue' \
            --output text)
          {
            echo "execution-role=${EXECUTION_ROLE}"
            echo "task-role=${TASK_ROLE}"
            echo "subnet-ids=${SUBNET_IDS}"
            echo "security-group-id=${SECURITY_GROUP_ID}"
            echo "frontend-target-group=${FRONTEND_TARGET_GROUP}"
            echo "backend-target-group=${BACKEND_TARGET_GROUP}"
          } >> $GITHUB_OUTPUT

      - name: Update task definition
        id: update-task-def
        env:
          ALB_DNS: ${{ needs.build-and-push.outputs.alb-dns }}
          AWS_REGION: ${{ env.AWS_REGION }}
          IMAGE_TAG: ${{ needs.build-and-push.outputs.image-tag }}
          EXECUTION_ROLE: ${{ steps.get-outputs.outputs.execution-role }}
          TASK_ROLE: ${{ steps.get-outputs.outputs.task-role }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "--- Debugging Update task definition ---"
          echo "ALB_DNS: $ALB_DNS"
          echo "AWS_REGION: $AWS_REGION"
          echo "IMAGE_TAG: $IMAGE_TAG"
          echo "EXECUTION_ROLE: $EXECUTION_ROLE"
          echo "TASK_ROLE: $TASK_ROLE"
          
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          
          BACKEND_IMAGE="${ECR_REGISTRY}/python-s3-webapp-backend:${IMAGE_TAG}"
          FRONTEND_IMAGE="${ECR_REGISTRY}/python-s3-webapp-frontend:${IMAGE_TAG}"
          
          echo "BACKEND_IMAGE: $BACKEND_IMAGE"
          echo "FRONTEND_IMAGE: $FRONTEND_IMAGE"
          echo "AWS_ACCOUNT_ID: $AWS_ACCOUNT_ID"
          echo "--- End Debugging ---"

          # Validate required inputs
          for var in AWS_ACCOUNT_ID ALB_DNS AWS_REGION IMAGE_TAG EXECUTION_ROLE TASK_ROLE BACKEND_IMAGE FRONTEND_IMAGE ECR_REGISTRY; do
            if [ -z "${!var}" ]; then
              echo "Error: $var is not set"
              exit 1
            fi
          done
          
          # Read and process task definition
          if [ ! -f .aws/task-definition.json ]; then
            echo "Error: task-definition.json not found"
            exit 1
          fi
          
          # Use jq to substitute variables and update the task definition (remove secrets)
          TASK_DEF=$(jq \
            --arg AWS_ACCOUNT_ID "$AWS_ACCOUNT_ID" \
            --arg AWS_REGION "$AWS_REGION" \
            --arg IMAGE_TAG "$IMAGE_TAG" \
            --arg ALB_DNS "$ALB_DNS" \
            --arg EXECUTION_ROLE "$EXECUTION_ROLE" \
            --arg TASK_ROLE "$TASK_ROLE" \
            --arg BACKEND_IMAGE "$BACKEND_IMAGE" \
            --arg FRONTEND_IMAGE "$FRONTEND_IMAGE" \
            --arg S3_BUCKET_NAME "$S3_BUCKET_NAME" \
            --arg AWS_ACCESS_KEY_ID "$AWS_ACCESS_KEY_ID" \
            --arg AWS_SECRET_ACCESS_KEY "$AWS_SECRET_ACCESS_KEY" \
            --arg GEMINI_API_KEY "$GEMINI_API_KEY" \
            '
            (
              walk(if type == "string" then
                gsub("\\${AWS_ACCOUNT_ID}"; $AWS_ACCOUNT_ID) |
                gsub("\\${AWS_REGION}"; $AWS_REGION) |
                gsub("\\${IMAGE_TAG}"; $IMAGE_TAG) |
                gsub("\\${ALB_DNS}"; $ALB_DNS)
              else . end)
            ) |
            # Remove secrets section to avoid Secrets Manager dependency
            .containerDefinitions[] |= (del(.secrets)) |
            # Add environment variables for AWS credentials to backend container
            .containerDefinitions[0].environment += [
              {"name": "AWS_ACCESS_KEY_ID", "value": $AWS_ACCESS_KEY_ID},
              {"name": "AWS_SECRET_ACCESS_KEY", "value": $AWS_SECRET_ACCESS_KEY},
              {"name": "S3_BUCKET_NAME", "value": $S3_BUCKET_NAME},
              {"name": "GEMINI_API_KEY", "value": $GEMINI_API_KEY}
            ] |
            .executionRoleArn = $EXECUTION_ROLE |
            .taskRoleArn = $TASK_ROLE |
            .containerDefinitions[0].image = $BACKEND_IMAGE |
            .containerDefinitions[1].image = $FRONTEND_IMAGE
            ' .aws/task-definition.json)

          echo "$TASK_DEF" > updated-task-definition.json
          
          # Register the task definition
          TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://updated-task-definition.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)
          
          if [ -z "$TASK_DEF_ARN" ]; then
            echo "Error: Failed to register task definition"
            exit 1
          fi
          
          echo "Successfully registered task definition: ${TASK_DEF_ARN}"
          echo "arn=${TASK_DEF_ARN}" >> $GITHUB_OUTPUT

      - name: Deploy to ECS
        run: |
          # Add delay to handle AWS eventual consistency
          echo "Waiting for ECS cluster to be fully available..."
          sleep 30
          
          # Retry logic for service deployment
          for i in {1..3}; do
            echo "Attempt $i: Deploying to ECS..."
            
            if aws ecs create-service \
              --cluster ${{ env.APP_NAME }}-cluster \
              --service-name ${{ env.APP_NAME }}-service \
              --task-definition ${{ steps.update-task-def.outputs.arn }} \
              --desired-count 1 \
              --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[${{ steps.get-outputs.outputs.subnet-ids }}],securityGroups=[${{ steps.get-outputs.outputs.security-group-id }}],assignPublicIp=ENABLED}" \
              --load-balancers targetGroupArn=${{ steps.get-outputs.outputs.frontend-target-group }},containerName=frontend,containerPort=80 targetGroupArn=${{ steps.get-outputs.outputs.backend-target-group }},containerName=backend,containerPort=5000; then
              echo "Service created successfully"
              break
            elif aws ecs update-service \
               --cluster ${{ env.APP_NAME }}-cluster \
               --service ${{ env.APP_NAME }}-service \
               --task-definition ${{ steps.update-task-def.outputs.arn }} \
               --force-new-deployment; then
              echo "Service updated successfully"
              break
            else
              echo "Attempt $i failed. Waiting 30 seconds before retry..."
              if [ $i -lt 3 ]; then
                sleep 30
              else
                echo "All attempts failed. Exiting."
                exit 1
              fi
            fi
          done

      - name: Wait for service stability
        run: |
          aws ecs wait services-stable \
            --cluster ${{ env.APP_NAME }}-cluster \
            --services ${{ env.APP_NAME }}-service
