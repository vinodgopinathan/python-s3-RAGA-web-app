# Python S3 Web Application

A modern web application with React frontend and Python Flask backend that allows users to query and analyze files stored in Amazon S3 using Large Language Models (LLMs). The application supports natural language queries and can extract text from various file formats including PDFs.

## ğŸš€ Features

- **Natural Language Queries**: Ask questions about your S3 files in plain English
- **Multi-format Support**: Analyze PDFs, text files, CSVs, and more
- **LLM Integration**: Supports both Gemini and OpenAI models
- **Real-time Processing**: Fast file content extraction and analysis
- **Full Prompt Transparency**: See exactly what prompt is sent to the LLM
- **Multiple Deployment Options**: Local development and AWS ECS

## ğŸ— Architecture

- **Frontend**: React.js with Material-UI
- **Backend**: Python Flask with AWS S3 integration
- **LLM Providers**: Google Gemini, OpenAI GPT
- **File Processing**: PyPDF2 for PDF text extraction
- **Deployment**: Docker containers with multiple configuration options

## ğŸ“ Project Structure

```
python-s3-web-app/
â”œâ”€â”€ frontend/                 # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js           # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css          # Styling
â”‚   â”‚   â””â”€â”€ index.js         # Entry point
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ Dockerfile           # Frontend container configuration
â”œâ”€â”€ backend/                 # Python Flask backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.py          # Flask application
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ llm_helper.py    # LLM integration and processing
â”‚   â”‚       â””â”€â”€ s3_helper.py     # S3 file operations
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Backend container configuration
â”œâ”€â”€ infrastructure/         # AWS CloudFormation templates
â”œâ”€â”€ .github/workflows/      # GitHub Actions for CI/CD
â”œâ”€â”€ docker-compose.yml      # Local development configuration
â”œâ”€â”€ docker-compose.yml     # Development configuration
â”œâ”€â”€ docker-compose.ecs.yml  # AWS ECS configuration
â”œâ”€â”€ DEPLOYMENT.md           # Detailed deployment guide
â””â”€â”€ LLM_CONFIGURATION.md    # LLM setup and configuration
```

## ğŸš€ Quick Start

### Local Development

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd python-s3-web-app
   ```

2. **Set up environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your AWS credentials and API keys
   ```

3. **Start the application**:
   ```bash
   docker compose up -d
   ```

4. **Access the application**:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:5001
   - Health Check: http://localhost:5001/health

## ğŸ“– Deployment Options

This application supports multiple deployment configurations:

- **ğŸ  Local Development**: Docker Compose for easy local testing  
- **â˜ï¸ AWS ECS**: Containerized deployment with auto-scaling

For detailed deployment instructions, see [DEPLOYMENT.md](DEPLOYMENT.md).

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `AWS_ACCESS_KEY_ID` | AWS access key | âœ… |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key | âœ… |
| `S3_BUCKET_NAME` | S3 bucket containing files | âœ… |
| `PROVIDER` | LLM provider (gemini/openai) | âœ… |
| `MODEL` | LLM model name | âœ… |
| `GEMINI_API_KEY` | Google Gemini API key | Conditional |
| `OPENAI_API_KEY` | OpenAI API key | Conditional |

### LLM Configuration

For detailed LLM setup instructions, see [LLM_CONFIGURATION.md](LLM_CONFIGURATION.md).

## ğŸ’¬ Usage Examples

Try these natural language queries:

- "List me files that contain the word 'cook'"
- "What files discuss machine learning?"
- "Show me all PDF files about project management"
- "Find documents related to data analysis"

## ğŸ›  Development

### Prerequisites

- Docker and Docker Compose
- Node.js 18+ (for local frontend development)
- Python 3.9+ (for local backend development)

### Local Development Setup

```bash
# Install backend dependencies
cd backend
pip install -r requirements.txt

# Install frontend dependencies  
cd ../frontend
npm install

# Run without Docker (requires separate terminals)
cd ../backend && python src/app.py
cd ../frontend && npm start
```

## ğŸ§ª Testing

```bash
# Test local build
docker compose build --no-cache
docker compose up -d

# Run health checks
curl http://localhost:5001/health
curl http://localhost:3000

# Clean up
docker compose down -v
```

## ğŸ” Monitoring

### Health Checks

- Backend: `GET /health`
- Frontend: Standard HTTP health check

### Logs

```bash
# View logs
docker compose logs -f backend
docker compose logs -f frontend

# AWS ECS logs available in CloudWatch
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test locally using `docker compose up`
5. Submit a pull request

## ğŸ“„ License

This project is open source. See the repository for license details.

## ğŸ†˜ Support

For issues and questions:
1. Check the [DEPLOYMENT.md](DEPLOYMENT.md) guide
2. Review GitHub Actions logs for deployment issues
3. Open an issue in the repository